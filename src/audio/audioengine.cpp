#include "audioengine.h"
#include <QMediaDevices>
#include <QAudioDevice>
#include <QDebug>
#include <cmath>

AudioEngine::AudioEngine(QObject *parent)
    : QObject(parent), m_audioSink(nullptr), m_audioSinkDevice(nullptr), m_audioSource(nullptr),
      m_audioSourceDevice(nullptr), m_micEnabled(false), m_micPollTimer(nullptr) {

    // Output format: K4 uses 12kHz stereo Float32 PCM (L=Main RX, R=Sub RX)
    m_outputFormat.setSampleRate(12000);
    m_outputFormat.setChannelCount(2);
    m_outputFormat.setSampleFormat(QAudioFormat::Float);

    // Input format: Use native 48kHz for microphone capture (most hardware supports this)
    // We'll resample to 12kHz before encoding for K4 TX
    m_inputFormat.setSampleRate(48000);
    m_inputFormat.setChannelCount(1);
    m_inputFormat.setSampleFormat(QAudioFormat::Float);

    // Create timer for polling microphone data (more reliable than readyRead signal)
    m_micPollTimer = new QTimer(this);
    m_micPollTimer->setInterval(10); // Poll every 10ms for low latency
    connect(m_micPollTimer, &QTimer::timeout, this, &AudioEngine::onMicDataReady);

    // Create feed timer for jitter-buffered RX audio playback
    m_feedTimer = new QTimer(this);
    m_feedTimer->setInterval(FEED_INTERVAL_MS);
    connect(m_feedTimer, &QTimer::timeout, this, &AudioEngine::feedAudioDevice);

    // Setup audio input immediately so mic testing works without radio connection
    setupAudioInput();
}

AudioEngine::~AudioEngine() {
    stop();
}

bool AudioEngine::start() {
    bool outputOk = setupAudioOutput();

    if (outputOk) {
        m_feedTimer->start();
    }

    // Setup audio input if not already done (it's also called in constructor)
    bool inputOk = (m_audioSource != nullptr) || setupAudioInput();

    Q_UNUSED(inputOk);

    return outputOk;
}

void AudioEngine::stop() {
    // Stop feed timer and clear jitter buffer
    if (m_feedTimer) {
        m_feedTimer->stop();
    }
    m_audioQueue.clear();
    m_prebuffering = true;

    // Stop mic polling timer
    if (m_micPollTimer) {
        m_micPollTimer->stop();
    }

    if (m_audioSink) {
        m_audioSink->stop();
        delete m_audioSink;
        m_audioSink = nullptr;
        m_audioSinkDevice = nullptr;
    }

    if (m_audioSource) {
        m_audioSource->stop();
        delete m_audioSource;
        m_audioSource = nullptr;
        m_audioSourceDevice = nullptr;
    }

    m_micBuffer.clear();
}

bool AudioEngine::setupAudioOutput() {
    // Find the output device - use selected device or fall back to default
    QAudioDevice outputDevice;

    if (!m_selectedOutputDeviceId.isEmpty()) {
        // Try to find the selected device
        for (const QAudioDevice &device : QMediaDevices::audioOutputs()) {
            if (device.id() == m_selectedOutputDeviceId) {
                outputDevice = device;
                break;
            }
        }
    }

    // Fall back to default if selected device not found
    if (outputDevice.isNull()) {
        outputDevice = QMediaDevices::defaultAudioOutput();
    }

    if (outputDevice.isNull()) {
        qWarning() << "AudioEngine: No audio output device available";
        return false;
    }

    if (!outputDevice.isFormatSupported(m_outputFormat)) {
        qWarning() << "AudioEngine: 12kHz output format not supported by device";
        return false;
    }

    m_audioSink = new QAudioSink(outputDevice, m_outputFormat, this);
    m_audioSink->setBufferSize(OUTPUT_BUFFER_SIZE);

    m_audioSinkDevice = m_audioSink->start();
    if (!m_audioSinkDevice) {
        qWarning() << "AudioEngine: Failed to start audio output";
        delete m_audioSink;
        m_audioSink = nullptr;
        return false;
    }

    // Apply current volume setting to the newly created sink
    m_audioSink->setVolume(m_volume);

    return true;
}

bool AudioEngine::setupAudioInput() {
    // Find the input device - use selected device or fall back to default
    QAudioDevice inputDevice;

    if (!m_selectedMicDeviceId.isEmpty()) {
        // Try to find the selected device
        for (const QAudioDevice &device : QMediaDevices::audioInputs()) {
            if (device.id() == m_selectedMicDeviceId) {
                inputDevice = device;
                break;
            }
        }
    }

    // Fall back to default if selected device not found
    if (inputDevice.isNull()) {
        inputDevice = QMediaDevices::defaultAudioInput();
    }

    if (inputDevice.isNull()) {
        qWarning() << "AudioEngine: No audio input device available";
        return false;
    }

    if (!inputDevice.isFormatSupported(m_inputFormat)) {
        qWarning() << "AudioEngine: 48kHz input format not supported by device";
        return false;
    }

    m_audioSource = new QAudioSource(inputDevice, m_inputFormat, this);
    m_audioSource->setBufferSize(INPUT_BUFFER_SIZE);

    // Don't start mic by default - user must enable
    return true;
}

void AudioEngine::enqueueAudio(const QByteArray &pcmData) {
    if (pcmData.isEmpty())
        return;

    // Overflow protection: drop oldest if queue too deep
    while (m_audioQueue.size() >= MAX_QUEUE_PACKETS) {
        m_audioQueue.dequeue();
    }

    m_audioQueue.enqueue(pcmData);
}

void AudioEngine::flushQueue() {
    m_audioQueue.clear();
    m_prebuffering = true;
}

void AudioEngine::feedAudioDevice() {
    if (!m_audioSinkDevice || m_audioQueue.isEmpty())
        return;

    // Wait for prebuffer to fill before starting playback
    if (m_prebuffering) {
        if (m_audioQueue.size() < PREBUFFER_PACKETS)
            return;
        m_prebuffering = false;
    }

    // Write as many queued packets as the sink can accept
    // Volume/routing/balance is applied here at playback time so slider
    // changes take effect instantly regardless of queue depth
    while (!m_audioQueue.isEmpty()) {
        const QByteArray &front = m_audioQueue.head();
        int bytesFree = m_audioSink->bytesFree();
        if (bytesFree < front.size())
            break;

        QByteArray packet = m_audioQueue.dequeue();
        applyMixAndVolume(packet);
        m_audioSinkDevice->write(packet);
    }
}

// Compute one output channel's mix from main/sub sources
static inline float mixChannel(float mainSample, float subSample, AudioEngine::MixSource src, float mainVol,
                               float subVol) {
    switch (src) {
    case AudioEngine::MixA:
        return mainSample * mainVol;
    case AudioEngine::MixB:
        return subSample * subVol;
    case AudioEngine::MixAB:
        return mainSample * mainVol + subSample * subVol;
    case AudioEngine::MixNegA:
        return -mainSample * mainVol;
    }
    return 0.0f;
}

void AudioEngine::applyMixAndVolume(QByteArray &packet) {
    float *samples = reinterpret_cast<float *>(packet.data());
    int totalFloats = packet.size() / sizeof(float);
    int sampleCount = totalFloats / 2;

    // Pre-compute BL balance gains (BAL mode only, applied after MX routing)
    float balLeftGain = 1.0f, balRightGain = 1.0f;
    if (m_balanceMode == 1) {
        balLeftGain = qBound(0.0f, (50.0f - m_balanceOffset) / 50.0f, 1.0f);
        balRightGain = qBound(0.0f, (50.0f + m_balanceOffset) / 50.0f, 1.0f);
    }

    for (int i = 0; i < sampleCount; i++) {
        float mainSample = samples[i * 2];    // Left channel (Main RX / VFO A)
        float subSample = samples[i * 2 + 1]; // Right channel (Sub RX / VFO B)

        // Step 1: SUB RX off — both channels get main audio only, sub slider has no effect
        // BL balance still applies (L/R gain is independent of SUB RX state)
        if (m_subMuted) {
            float s = mainSample * m_mainVolume;
            samples[i * 2] = qBound(-1.0f, s * balLeftGain, 1.0f);
            samples[i * 2 + 1] = qBound(-1.0f, s * balRightGain, 1.0f);
            continue;
        }

        // Step 2: SUB RX on — apply MX routing
        float left, right;
        if (m_balanceMode == 0) {
            // NOR mode: main slider controls main, sub slider controls sub
            left = mixChannel(mainSample, subSample, m_mixLeft, m_mainVolume, m_subVolume);
            right = mixChannel(mainSample, subSample, m_mixRight, m_mainVolume, m_subVolume);
        } else {
            // BAL mode: mainVolume controls both receivers (sub slider repurposed as balance)
            left = mixChannel(mainSample, subSample, m_mixLeft, m_mainVolume, m_mainVolume);
            right = mixChannel(mainSample, subSample, m_mixRight, m_mainVolume, m_mainVolume);

            // Step 3: Apply BL balance (L/R gain adjustment after MX routing)
            left *= balLeftGain;
            right *= balRightGain;
        }

        // Step 4: Clamp
        samples[i * 2] = qBound(-1.0f, left, 1.0f);
        samples[i * 2 + 1] = qBound(-1.0f, right, 1.0f);
    }
}

void AudioEngine::setMicEnabled(bool enabled) {
    if (m_micEnabled == enabled)
        return;

    m_micEnabled = enabled;

    if (!m_audioSource) {
        qWarning() << "AudioEngine: m_audioSource is NULL - mic not available";
        return;
    }

    if (enabled) {
        m_audioSourceDevice = m_audioSource->start();
        if (m_audioSourceDevice) {
            // Use timer-based polling instead of readyRead signal
            // (readyRead doesn't fire reliably on all platforms)
            m_micPollTimer->start();
        } else {
            qWarning() << "AudioEngine: Failed to start microphone device";
        }
    } else {
        m_micPollTimer->stop();
        m_audioSource->stop();
        m_audioSourceDevice = nullptr;
        m_micBuffer.clear(); // Clear any buffered data
    }
}

QByteArray AudioEngine::resample48kTo12k(const QByteArray &input48k) {
    // Simple 4:1 decimation with averaging filter
    // 48kHz / 4 = 12kHz
    const float *inputSamples = reinterpret_cast<const float *>(input48k.constData());
    int inputCount = input48k.size() / sizeof(float);
    int outputCount = inputCount / 4;

    QByteArray output12k;
    output12k.reserve(outputCount * sizeof(float));

    for (int i = 0; i < outputCount; i++) {
        // Average 4 samples for simple low-pass filtering
        int srcIdx = i * 4;
        float sum = 0.0f;
        int count = 0;
        for (int j = 0; j < 4 && (srcIdx + j) < inputCount; j++) {
            sum += inputSamples[srcIdx + j];
            count++;
        }
        float avg = (count > 0) ? (sum / count) : 0.0f;
        output12k.append(reinterpret_cast<const char *>(&avg), sizeof(float));
    }

    return output12k;
}

void AudioEngine::onMicDataReady() {
    if (!m_audioSourceDevice || !m_micEnabled)
        return;

    QByteArray data48k = m_audioSourceDevice->readAll();
    if (data48k.isEmpty()) {
        // No data available yet - this is normal, just wait for next poll
        return;
    }

    // Resample from 48kHz to 12kHz
    QByteArray data12k = resample48kTo12k(data48k);

    // Emit raw resampled data for any listeners that want it
    emit microphoneData(data12k);

    // Convert Float32 to S16LE, apply gain, and buffer for frame-based emission
    const float *floatData = reinterpret_cast<const float *>(data12k.constData());
    int floatSamples = data12k.size() / sizeof(float);

    // Calculate RMS level AFTER gain for meter display (shows what will be transmitted)
    float sumSquares = 0.0f;

    // Convert and append to buffer with gain applied
    for (int i = 0; i < floatSamples; i++) {
        // Apply mic gain and clamp (MIC_GAIN_SCALE makes 50% slider = unity gain)
        float sample = qBound(-1.0f, floatData[i] * m_micGain * MIC_GAIN_SCALE, 1.0f);
        qint16 s16Sample = static_cast<qint16>(sample * 32767.0f);

        // Accumulate for RMS calculation (after gain)
        sumSquares += sample * sample;

        // Append as little-endian bytes
        m_micBuffer.append(reinterpret_cast<const char *>(&s16Sample), sizeof(qint16));
    }

    // Emit RMS level for meter display
    float rmsLevel = (floatSamples > 0) ? std::sqrt(sumSquares / floatSamples) : 0.0f;
    emit micLevelChanged(rmsLevel);

    // Emit complete frames (240 samples = 480 bytes S16LE each)
    while (m_micBuffer.size() >= FRAME_BYTES_S16LE) {
        QByteArray frame = m_micBuffer.left(FRAME_BYTES_S16LE);
        m_micBuffer.remove(0, FRAME_BYTES_S16LE);
        emit microphoneFrame(frame);
    }
}

void AudioEngine::setVolume(float volume) {
    m_volume = qBound(0.0f, volume, 1.0f);
    if (m_audioSink) {
        m_audioSink->setVolume(m_volume);
    }
}

void AudioEngine::setMainVolume(float volume) {
    m_mainVolume = qBound(0.0f, volume, 1.0f);
}

void AudioEngine::setSubVolume(float volume) {
    m_subVolume = qBound(0.0f, volume, 1.0f);
}

void AudioEngine::setSubMuted(bool muted) {
    m_subMuted = muted;
}

void AudioEngine::setAudioMix(int left, int right) {
    m_mixLeft = static_cast<MixSource>(qBound(0, left, 3));
    m_mixRight = static_cast<MixSource>(qBound(0, right, 3));
}

void AudioEngine::setBalanceMode(int mode) {
    m_balanceMode = qBound(0, mode, 1);
}

void AudioEngine::setBalanceOffset(int offset) {
    m_balanceOffset = qBound(-50, offset, 50);
}

void AudioEngine::setMicGain(float gain) {
    m_micGain = qBound(0.0f, gain, 1.0f);
}

void AudioEngine::setMicDevice(const QString &deviceId) {
    if (m_selectedMicDeviceId != deviceId) {
        m_selectedMicDeviceId = deviceId;

        // If mic is currently enabled, we need to restart it with the new device
        bool wasEnabled = m_micEnabled;
        if (wasEnabled) {
            setMicEnabled(false);
        }

        // Recreate the audio source with the new device
        if (m_audioSource) {
            delete m_audioSource;
            m_audioSource = nullptr;
        }
        setupAudioInput();

        if (wasEnabled) {
            setMicEnabled(true);
        }
    }
}

QString AudioEngine::micDeviceId() const {
    return m_selectedMicDeviceId;
}

QList<QPair<QString, QString>> AudioEngine::availableInputDevices() {
    QList<QPair<QString, QString>> devices;

    // Add "System Default" as the first option
    devices.append(qMakePair(QString(""), QString("System Default")));

    // Add all available input devices
    for (const QAudioDevice &device : QMediaDevices::audioInputs()) {
        devices.append(qMakePair(QString(device.id()), device.description()));
    }

    return devices;
}

void AudioEngine::setOutputDevice(const QString &deviceId) {
    if (m_selectedOutputDeviceId != deviceId) {
        m_selectedOutputDeviceId = deviceId;

        // Restart audio output with the new device if currently running
        if (m_audioSink) {
            m_audioSink->stop();
            delete m_audioSink;
            m_audioSink = nullptr;
            m_audioSinkDevice = nullptr;

            setupAudioOutput();
        }
    }
}

QString AudioEngine::outputDeviceId() const {
    return m_selectedOutputDeviceId;
}

QList<QPair<QString, QString>> AudioEngine::availableOutputDevices() {
    QList<QPair<QString, QString>> devices;

    // Add "System Default" as the first option
    devices.append(qMakePair(QString(""), QString("System Default")));

    // Add all available output devices
    for (const QAudioDevice &device : QMediaDevices::audioOutputs()) {
        devices.append(qMakePair(QString(device.id()), device.description()));
    }

    return devices;
}
